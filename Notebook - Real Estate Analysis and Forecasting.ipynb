{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36668657",
   "metadata": {},
   "source": [
    "Main Objectives:\n",
    "\n",
    "The primary objective of this project is to utilize time series modeling techniques to identify the top 5 zip codes for investment opportunities for a fictional real estate investment firm. The focus will predominantly be on maximizing profit margins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca7110d",
   "metadata": {},
   "source": [
    "Problem Statement:\n",
    "\n",
    "The real estate investment firm has tasked us, as consultants, with identifying the top 5 zip codes for investment opportunities. In this context, \"best\" is defined primarily in terms of profit margins. The recommendation should prioritize zip codes with the highest potential for profitability, based on historical real estate price data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5abfd1",
   "metadata": {},
   "source": [
    "Key Questions to Address:\n",
    "\n",
    "1.How can profit margins be maximized through the selection of zip codes for investment?\n",
    "2.Which time series modeling techniques are most suitable for predicting real estate prices and identifying profitable investment opportunities?\n",
    "3.How will the recommendation incorporate considerations of risk and uncertainty associated with real estate investments?\n",
    "4.What strategies can be employed to communicate the recommendation effectively to stakeholders?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec03f5a6",
   "metadata": {},
   "source": [
    "Key Deliverables:\n",
    "\n",
    "-Identification of the top 5 zip codes with the highest potential for profit margins.\n",
    "-Time series models forecasting real estate prices for the selected zip codes.\n",
    "-Analysis of profit potential, considering factors such as historical price trends, volatility, and investment horizon.\n",
    "-Evaluation of the robustness of the recommendation and sensitivity to changes in assumptions.\n",
    "-Presentation of findings through clear visualizations and a compelling narrative to facilitate decision-making by stakeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6217830",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0681705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pmdarima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2475b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade phoenix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68c58d5",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361876e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure plots are displayed inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Suppress specific warning\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set()\n",
    "\n",
    "# Importing required libraries for time series analysis\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import pmdarima as pm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error as calc_MSE\n",
    "from math import sqrt\n",
    "from matplotlib.pylab import rcParams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcd8f10",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e57b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying all columns\n",
    "pd.set_option(\"display.max_columns\",None)\n",
    "# load the data from the csv file\n",
    "df = pd.read_csv('zillow_data.csv')\n",
    "# display the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d2d1c",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc22b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a column of %ROI\n",
    "df[\"%ROI\"] = ((df[\"2018-04\"] / df[\"2012-01\"]) ** (1 / (2018-2012)) - 1) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82634c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a column of actual ROI\n",
    "df['ROI price'] = df[\"2018-04\"] - df[\"2012-01\"]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a516506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the columns in the dataset\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5efebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5bbb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check information about the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d573744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics of the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37027ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert wide format data to long format\n",
    "long_data = pd.melt(df, \n",
    "                    id_vars=['RegionID', 'RegionName', 'SizeRank', 'City', 'State', 'Metro', 'CountyName', '%ROI', 'ROI price'], \n",
    "                    var_name='Date')\n",
    "\n",
    "# Rename the RegionName column to Zipcode\n",
    "long_data = long_data.rename(columns={'RegionName': 'Zipcode', 'value': 'Price'})\n",
    "\n",
    "# Convert Zipcode to categorical data type\n",
    "long_data['Zipcode'] = long_data['Zipcode'].astype('str')\n",
    "\n",
    "# Convert Date to datetime format\n",
    "long_data['Date'] = pd.to_datetime(long_data['Date'], format='%Y-%m')\n",
    "\n",
    "long_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c24cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check columns of long data\n",
    "long_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c7b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics of the data\n",
    "long_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2742117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics of the data\n",
    "long_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61baf6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates within the dataset\n",
    "print(f'The number of duplicates within the dataset is: {long_data.duplicated().sum()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9239763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "missing_percentage = long_data.isna().sum() / len(long_data) * 100\n",
    "print(f'Percentage of missing values in each column:\\n{missing_percentage}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7d37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in the 'Metro' column with 'missing'\n",
    "long_data['Metro'] = long_data['Metro'].fillna('missing')\n",
    "\n",
    "# Checking for missing values after filling 'Metro' column\n",
    "missing_percentage = long_data.isna().sum() / len(long_data) * 100\n",
    "print(f'Percentage of missing values in each column after filling the \"Metro\" column:\\n{missing_percentage}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be94a352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical description of numerical variables\n",
    "num_description = long_data.describe()\n",
    "print(\"Statistical summary of numerical variables:\\n\", num_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422a6efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical description of categorical variables\n",
    "cat_description = long_data.describe(include=['object'])\n",
    "print(\"Statistical summary of categorical variables:\\n\", cat_description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d18ce92",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31765a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the most popular states in the dataset\n",
    "plt.figure(figsize=(12, 6))\n",
    "long_data['State'].value_counts()[:10].sort_values().plot(kind=\"barh\", color='lightgreen')\n",
    "plt.xlabel(\"Count\", fontsize=14)\n",
    "plt.ylabel(\"US States\", fontsize=14)\n",
    "plt.title(\"Top 10 Most Popular States\", fontsize=16, fontweight='bold')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92435881",
   "metadata": {},
   "source": [
    "Carlifonia is the most popular state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15e4370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the most popular counties in the dataset\n",
    "plt.figure(figsize=(12, 6))\n",
    "long_data['CountyName'].value_counts()[:10].sort_values().plot(kind=\"barh\", color='skyblue')\n",
    "plt.xlabel(\"Count\", fontsize=14)\n",
    "plt.ylabel(\"County Name\", fontsize=14)\n",
    "plt.title(\"Top 10 Most Popular Counties\", fontsize=16, fontweight='bold')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.gca().invert_yaxis()  \n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46ba42a",
   "metadata": {},
   "source": [
    "L.A. is the most popular county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8718929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the most popular cities in the dataset\n",
    "plt.figure(figsize=(12, 6))\n",
    "long_data['City'].value_counts()[:10].sort_values().plot(kind=\"barh\", color='salmon')\n",
    "plt.xlabel(\"Count\", fontsize=14)\n",
    "plt.ylabel(\"US Cities\", fontsize=14)\n",
    "plt.title(\"Top 10 Most Popular Cities\", fontsize=16, fontweight='bold')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.gca().invert_yaxis()  \n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9def18cf",
   "metadata": {},
   "source": [
    "New York is the most popular city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f951ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by mean %ROI and selecting top 30 zipcodes\n",
    "grouped_roi = long_data.groupby('Zipcode')\n",
    "roi_mean = grouped_roi['%ROI'].mean()\n",
    "roi_mean_df = roi_mean.reset_index(name='% ROI')\n",
    "roi_mean_df = roi_mean_df.sort_values(by='% ROI', ascending=False)\n",
    "top_30_zipcodes_roi = roi_mean_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6735e1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the %ROI by zipcode\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.bar(top_30_zipcodes_roi['Zipcode'], top_30_zipcodes_roi['% ROI'], color='skyblue')\n",
    "plt.xlabel('Zipcode', fontsize=15)\n",
    "plt.ylabel('% ROI', fontsize=15)\n",
    "plt.title('% Return On Investment by Zipcode', fontsize=20)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5ac49c",
   "metadata": {},
   "source": [
    "According to the chart, it appears that zipcode 85035 stands out as the most lucrative area, boasting a substantial 22.8% return on investment (ROI) between 2012 and 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60f9c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data series to check the prices of houses over time\n",
    "time_series = long_data.copy()\n",
    "time_series.set_index(\"Date\", inplace=True)\n",
    "time_series = time_series[\"Price\"]\n",
    "\n",
    "# Plotting mean house price\n",
    "plt.figure(figsize=(15, 10))\n",
    "time_series.resample(\"A\").mean().plot(color='skyblue')\n",
    "plt.ylabel(\"Mean Price\", fontsize=15)\n",
    "plt.title(\"Mean House Price from 1996 to 2018-USA\", fontsize=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520aecb4",
   "metadata": {},
   "source": [
    "This indicates an upward trend in housing prices from 1996 to 2008, followed by a sharp decline during the housing market crash. Subsequently, prices stabilized around 2012, after which they began to rise again until 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1eaaef",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78cbfd1",
   "metadata": {},
   "source": [
    "When working with time series models, it's typically assumed that the data is stationary, meaning that its mean, variance, and autocorrelation remain constant across different time periods.\n",
    "\n",
    "Having a stationary time series simplifies the model development process and ensures efficiency. Before proceeding with modeling, the data undergoes checks for stationarity through methods like the Dickey Fuller test and examining rolling means.\n",
    "\n",
    "If the data is found to be non-stationary, differencing is applied to transform it into a stationary form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325af1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Check for non-numeric values in the 'Price' column\n",
    "non_numeric_values = long_data[~long_data['Price'].apply(lambda x: str(x).replace('.', '').isdigit())]\n",
    "\n",
    "# Handle non-numeric values (replace with NaN in this example)\n",
    "long_data['Price'] = pd.to_numeric(long_data['Price'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in the 'Price' column\n",
    "long_data.dropna(subset=['Price'], inplace=True)\n",
    "\n",
    "# Filter data for the top 5 zipcodes based on %ROI\n",
    "zipcode = long_data.sort_values('%ROI', ascending=False)['Zipcode'].unique()[:5]\n",
    "top_5 = long_data[long_data['Zipcode'].isin(zipcode)]\n",
    "\n",
    "# Group data by date and zipcode, and calculate the mean price for each group starting from 2012\n",
    "grouped_5 = top_5.groupby(['Date', 'Zipcode'])['Price'].mean().reset_index()\n",
    "final_df = grouped_5[grouped_5['Date'] >= \"2005-01-01\"]\n",
    "\n",
    "# Check the columns present in final_df\n",
    "print(final_df.columns)\n",
    "\n",
    "# Drop unnecessary columns if they exist\n",
    "columns_to_drop = ['RegionID', 'SizeRank', '%ROI', 'ROI price']\n",
    "final_df.drop(columns_to_drop, axis=1, errors='ignore', inplace=True)\n",
    "\n",
    "# Set Date as index\n",
    "final_df.set_index('Date', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dfd95c",
   "metadata": {},
   "source": [
    "# Visualizing Home Prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4c2804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting home prices by zipcodes\n",
    "colors = ['green', 'orange', 'blue', 'red', 'purple']  \n",
    "line_styles = ['-', '--', '-.', ':', '-']  \n",
    "\n",
    "for i in range(5):\n",
    "    final_df[final_df['Zipcode'] == zipcode[i]].plot(y='Price', \n",
    "                                                      label=f\"Zone: {zipcode[i]}\", \n",
    "                                                      color=colors[i],\n",
    "                                                      linestyle=line_styles[i],\n",
    "                                                      figsize=(15, 8))\n",
    "plt.title(\"Trend of Home Prices by Zone\", fontsize=20)  \n",
    "plt.xlabel('Year', fontsize=15)  \n",
    "plt.ylabel('Price', fontsize=15) \n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60df7ef",
   "metadata": {},
   "source": [
    "# Calculating and Visualizing Monthly Returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9e75f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column called \"ret\" representing monthly returns on investment\n",
    "for i in range(5):\n",
    "    final_df[f'ret_{i}'] = final_df.groupby('Zipcode')['Price'].pct_change()\n",
    "\n",
    "# Plot the monthly returns of each zipcode\n",
    "for i in range(5):\n",
    "    final_df.plot(y=f'ret_{i}', figsize=(15, 10), label=f\"Zipcode: {zipcode[i]}\")\n",
    "plt.title(f'Monthly Returns per Zipcode', fontsize=20)\n",
    "plt.xlabel('Date', fontsize=15)\n",
    "plt.ylabel('Returns (%)', fontsize=15)\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe72b1",
   "metadata": {},
   "source": [
    "# Checking for Stationarity with Rolling Mean and Standard Deviation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b7dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting rolling mean and standard deviation for each zipcode\n",
    "for i in range(5):\n",
    "    rollingmean = final_df[f'ret_{i}'].rolling(window=12, center=False).mean()\n",
    "    rollingstd = final_df[f'ret_{i}'].rolling(window=12, center=False).std()\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    original = plt.plot(final_df[f'ret_{i}'], \n",
    "                        color=colors[i],\n",
    "                        linestyle=line_styles[i],\n",
    "                        label=\"Original\")\n",
    "    mean = plt.plot(rollingmean, \n",
    "                    color='black',  \n",
    "                    linestyle='--',  \n",
    "                    label=\"Rolling Mean\")\n",
    "    std = plt.plot(rollingstd, \n",
    "                   color='grey',  \n",
    "                   linestyle='-.',  \n",
    "                   label=\"Rolling Std\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(f'Rolling Mean & Std Deviation for Zone: {zipcode[i]}', fontsize=20)  #\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)  \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4ed3cd",
   "metadata": {},
   "source": [
    "The above graphs reveal that certain states show non-stationarity. However, to confirm this, a Dickey Fuller test is conducted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfff594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series data for each zipcode\n",
    "ts_data = {}\n",
    "for zc in zipcode:\n",
    "    ts_data[zc] = final_df[final_df['Zipcode'] == zc]['Price'].diff().dropna()\n",
    "\n",
    "\n",
    "for zc, data in ts_data.items():\n",
    "    # Perform Dickey-Fuller test\n",
    "    results = adfuller(data)\n",
    "    print(f'ADFuller test p-value for zipcode: {zc}')\n",
    "    print('p-value:', results[1])\n",
    "    \n",
    "    if results[1] > 0.05:\n",
    "        print('Fail to reject the null hypothesis. Data is not stationary.\\n')\n",
    "        # Perform differencing\n",
    "        diff_data = data.diff().dropna()\n",
    "        # Apply Dickey-Fuller test again\n",
    "        results_diff = adfuller(diff_data)\n",
    "        print(f'ADFuller test p-value after differencing for zipcode: {zc}')\n",
    "        print('p-value:', results_diff[1])\n",
    "        if results_diff[1] > 0.05:\n",
    "            print('Fail to reject the null hypothesis even after differencing. Data might need further processing.\\n')\n",
    "        else:\n",
    "            print('Reject the null hypothesis after differencing. Data is now stationary.\\n')\n",
    "    else:\n",
    "        print('Reject the null hypothesis. Data is stationary.\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4e38e5",
   "metadata": {},
   "source": [
    "# Model Perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22d9501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating individual time series for each zip code\n",
    "ts_85035 = final_df[final_df['Zipcode'] == zipcode[0]]['Price'].diff().dropna()\n",
    "ts_85008 = final_df[final_df['Zipcode'] == zipcode[1]]['Price'].diff().dropna()\n",
    "ts_94590 = final_df[final_df['Zipcode'] == zipcode[2]]['Price'].diff().dropna()\n",
    "ts_94601 = final_df[final_df['Zipcode'] == zipcode[3]]['Price'].diff().dropna()\n",
    "ts_94804 = final_df[final_df['Zipcode'] == zipcode[4]]['Price'].diff().dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997c78ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that plots ACF and PACF plots\n",
    "def acf_pacf_plot(data, alags=40, plags=40):\n",
    "    \"\"\"\n",
    "    Plot ACF and PACF plots for the given data.\n",
    "\n",
    "    Parameters:\n",
    "    - data: Time series data for which ACF and PACF plots are to be plotted.\n",
    "    - alags: Number of lags to consider for ACF plot.\n",
    "    - plags: Number of lags to consider for PACF plot.\n",
    "    \"\"\"\n",
    "    # Create figure\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 8))\n",
    "    \n",
    "    # Make ACF plot\n",
    "    plot_acf(data, lags=alags, zero=False, ax=ax1)\n",
    "    ax1.set_title('Autocorrelation Function (ACF)')\n",
    "    \n",
    "    # Make PACF plot\n",
    "    plot_pacf(data, lags=plags, ax=ax2)\n",
    "    ax2.set_title('Partial Autocorrelation Function (PACF)')\n",
    "    \n",
    "    plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1b0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting ACF and PACF for the time series data related to zipcode 85035\n",
    "acf_pacf_plot(ts_85035)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf411339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using auto arima to find the best p,d,q for the model related to zipcode 85035\n",
    "model = pm.auto_arima(ts_85035, trace=True, error_action='ignore', suppress_warnings=True, stepwise=True)\n",
    "\n",
    "# Printing the summary of the best ARIMA model\n",
    "print(\"Summary of the best ARIMA model:\")\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62ba5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test sets\n",
    "train_85035 = ts_85035[:'2015-01']\n",
    "test_85035 = ts_85035['2015-02':]\n",
    "\n",
    "# Fitting an ARIMA Model on the training series using parameters from the AUTO ARIMA model\n",
    "# Initializing ARIMA model with the previously determined order\n",
    "ARIMAmodel = ARIMA(train_85035, order=(2, 0, 1))\n",
    "\n",
    "# Fitting the ARIMA model to the training data\n",
    "ARIMAmodel = ARIMAmodel.fit()\n",
    "\n",
    "# Printing the summary of the ARIMA model\n",
    "print(\"Summary of the ARIMA model:\")\n",
    "print(ARIMAmodel.summary())\n",
    "\n",
    "# Plotting diagnostics of the ARIMA model\n",
    "ARIMAmodel.plot_diagnostics(figsize=(18, 18))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a728b6",
   "metadata": {},
   "source": [
    "The residuals must exhibit no correlation and adhere to a normal distribution to meet the normality assumptions.\n",
    "\n",
    "The QQ-plot displayed in the lower-left quadrant indicates that the residuals conform to a linear trend line, suggesting a normal distribution.\n",
    "\n",
    "The correlogram plot in the lower-left quadrant reveals minimal correlations with lagged versions of the residuals, indicating the absence of apparent seasonality in our dataset.\n",
    "\n",
    "The histogram portrays a bell curve, signifying that the residuals follow a normal distribution, which is favorable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d69fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a table of the upper and lower limits\n",
    "pred = ARIMAmodel.get_prediction(start=pd.to_datetime('2015-02'), end=pd.to_datetime('2018-04'), dynamic=False)\n",
    "pred_conf = pred.conf_int()\n",
    "pred_conf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789b07d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting the training data against the test data\n",
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "# Plot observed values\n",
    "plt.plot(ts_85035.index, ts_85035, label='Observed', color=\"cornflowerblue\")\n",
    "\n",
    "# Plot predicted values\n",
    "plt.plot(pred.predicted_mean.index, pred.predicted_mean, label='Prediction Series', alpha=0.9, color=\"salmon\")\n",
    "\n",
    "# Plot the range for confidence intervals\n",
    "plt.fill_between(pred_conf.index, pred_conf.iloc[:, 0], pred_conf.iloc[:, 1], color='lightgray', alpha=0.5, label='Confidence Interval')\n",
    "\n",
    "# Set axes labels and title\n",
    "plt.xlabel('Date', fontsize=15)\n",
    "plt.ylabel('Returns', fontsize=15)\n",
    "plt.title('Testing Forecasting Model Performance', fontsize=20)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa7c4e7",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c90cb93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the RMSE for the model\n",
    "rmse = mean_squared_error(test_85035, pred.predicted_mean, squared=False)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbea58a",
   "metadata": {},
   "source": [
    "###### Forecasting for the next 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ARIMA model\n",
    "ARIMA_MODEL = ARIMA(ts_85035, \n",
    "                    order=(2,0,1), \n",
    "                    enforce_stationarity=False, \n",
    "                    enforce_invertibility=False)\n",
    "\n",
    "# Fit the model and print results\n",
    "full_output = ARIMA_MODEL.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(full_output.summary())\n",
    "\n",
    "# Forecast for the next 5 years (60 months)\n",
    "forecast = full_output.get_forecast(steps=60)\n",
    "\n",
    "# Get the forecasted values and the confidence intervals\n",
    "forecast_values = forecast.predicted_mean\n",
    "confidence_intervals = forecast.conf_int()\n",
    "\n",
    "# Print forecasted values and confidence intervals\n",
    "print(\"Forecasted Values:\")\n",
    "print(forecast_values)\n",
    "print(\"\\nConfidence Intervals:\")\n",
    "print(confidence_intervals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cac607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a forecast for the next 60 months after the last recorded date on our dataset.\n",
    "forecast = full_output.get_forecast(steps=60)\n",
    "future_prediction = forecast.conf_int()\n",
    "future_prediction['Price'] = forecast.predicted_mean\n",
    "future_prediction.columns = ['lower','upper','prediction'] \n",
    "future_prediction.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe2023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting our Forecast\n",
    "fig, ax = plt.subplots()\n",
    "ts_85035.plot(ax=ax, label='Real Values', c=\"blue\")\n",
    "\n",
    "future_prediction['prediction'].plot(ax=ax, label='Predicted Value', c=\"red\")\n",
    "\n",
    "ax.fill_between(x=future_prediction.index, y1=future_prediction['lower'], \n",
    "                y2=future_prediction['upper'], color='gray',\n",
    "                label='Confidence Interval')\n",
    "ax.legend() \n",
    "plt.ylabel(\"% Home Prices\", fontsize=15)\n",
    "plt.title('Average Monthly Returns - 85035 - With Forecasted Values & Confidence Intervals', fontsize=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d39d760",
   "metadata": {},
   "source": [
    "###### A forecast for every zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75398c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_predictions = {}\n",
    "\n",
    "# Iterate over each unique Zipcode in final_df\n",
    "for zipcode in final_df['Zipcode'].unique():\n",
    "    # Selecting series for the current Zipcode\n",
    "    series = final_df[final_df['Zipcode'] == zipcode]['Price']\n",
    "    \n",
    "    # Only consider data from 2011 onwards\n",
    "    recent_series = series['2011':]\n",
    "    \n",
    "    # Splitting the last 36 months of our series as a test dataset\n",
    "    train_series = recent_series[:'2016-04']\n",
    "    test_series = recent_series['2016-05':]\n",
    "    \n",
    "    # Auto ARIMA model\n",
    "    auto_model = pm.auto_arima(train_series, \n",
    "                     trace=True,\n",
    "                     error_action='ignore',\n",
    "                     suppress_warnings=True,\n",
    "                     stepwise=True,\n",
    "                     with_intercept=False)\n",
    "   \n",
    "    # Plug the optimal parameter values for our Training data into a SARIMAX model that fits our entire series\n",
    "    ARIMA_MODEL = SARIMAX(recent_series, \n",
    "                          order=auto_model.order, \n",
    "                          seasonal_order=auto_model.seasonal_order, \n",
    "                          enforce_stationarity=False, \n",
    "                          enforce_invertibility=False)\n",
    "\n",
    "    # Fit the model\n",
    "    output = ARIMA_MODEL.fit()\n",
    "\n",
    "    # Getting a forecast for the next 36 months after the last recorded date on our dataset\n",
    "    forecast = output.get_forecast(36)\n",
    "    prediction = forecast.conf_int()\n",
    "    prediction['Price'] = forecast.predicted_mean\n",
    "    prediction.columns = ['lower','upper','prediction'] \n",
    "    \n",
    "    # Adding the Zipcode's ROI to the zip_predictions dictionary\n",
    "    zip_predictions[zipcode] = ((prediction['prediction'][-1]) - (series[-1])) / (series[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029c3197",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Initialize dictionary to store forecasted values\n",
    "forecast_values = {}\n",
    "\n",
    "# Create a for loop to forecast for every zipcode\n",
    "for zipcode in final_df['Zipcode'].unique():\n",
    "    # Selecting the series for the current zipcode\n",
    "    series = final_df[final_df['Zipcode'] == zipcode]['Price']\n",
    "    \n",
    "    # Splitting the data into training and testing sets\n",
    "    train_series = series[:-60]  # Use all data except the last 60 months for training\n",
    "    test_series = series[-60:]   # Use the last 60 months for testing\n",
    "    \n",
    "    # Fit SARIMAX model\n",
    "    model = SARIMAX(train_series, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "    fitted_model = model.fit()\n",
    "    \n",
    "    # Forecast for the next 60 months\n",
    "    forecast = fitted_model.forecast(steps=60)\n",
    "    \n",
    "    # Store forecasted values in the dictionary\n",
    "    forecast_values[zipcode] = forecast\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "forecast_df = pd.DataFrame(forecast_values)\n",
    "\n",
    "# Plot the forecasted values\n",
    "plt.figure(figsize=(12, 6))\n",
    "for zipcode in forecast_df.columns:\n",
    "    plt.plot(forecast_df.index, forecast_df[zipcode], label=f'Zipcode: {zipcode}')\n",
    "plt.title('Forecasted Prices for Next 60 Months')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a8cdf3",
   "metadata": {},
   "source": [
    "##### Conclusion and Recommendation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dcfada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top five zipcodes with the highest ROI\n",
    "top_zipcodes = sorted(zip_predictions, key=zip_predictions.get, reverse=True)[:5]\n",
    "\n",
    "# Create a list of ROI values for the top five zipcodes\n",
    "roi_values = [zip_predictions[zipcode] for zipcode in top_zipcodes]\n",
    "\n",
    "# Create a bar graph of the top five zipcodes and their corresponding ROI values\n",
    "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
    "bars = plt.bar(top_zipcodes, roi_values, color='orange')  # Change bar color to orange\n",
    "\n",
    "# Add data labels to the bars\n",
    "for bar, roi in zip(bars, roi_values):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{roi:.2f}', \n",
    "             ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Zipcode', fontsize=15)\n",
    "plt.ylabel('ROI', fontsize=15)\n",
    "plt.title('Top Five Zipcodes with Highest ROI Forecast', fontsize=20)\n",
    "\n",
    "# Add grid for better visualization\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "plt.gcf().canvas.draw()  # Explicitly draw the figure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2391f7",
   "metadata": {},
   "source": [
    "Based on the graph depicted above, it's evident that the forecasted ROI for the zipcode 94804 is the highest among the top five zipcodes. Therefore, it would be advantageous for the investor to consider investing in this particular zipcode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1390d801",
   "metadata": {},
   "source": [
    "All Zipcodes exhibit promising forecasted prices, with positive trends, except for the 85035 zipcode.\n",
    "Based on the presented graph, we derive our top five recommendations along with their anticipated ROI over a three-year period.\n",
    "Consequently, the investor has the option to consider investing in any of the aforementioned zipcodes, except for 85035, which lacks a positive return on investment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
